<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"></meta><title>PutParquet</title><link rel="stylesheet" href="/nifi-docs/css/component-usage.css" type="text/css"></link></head><script type="text/javascript">window.onload = function(){if(self==top) { document.getElementById('nameHeader').style.display = "inherit"; } }</script><body><h1 id="nameHeader" style="display: none;">PutParquet</h1><h2>Description: </h2><p>Reads records from an incoming FlowFile using the provided Record Reader, and writes those records to a Parquet file. The schema for the Parquet file must be provided in the processor properties. This processor will first write a temporary dot file and upon successfully writing every record to the dot file, it will rename the dot file to it's final name. If the dot file cannot be renamed, the rename operation will be attempted up to 10 times, and if still not successful, the dot file will be deleted and the flow file will be routed to failure.  If any error occurs while reading records from the input, or writing records to the output, the entire dot file will be removed and the flow file will be routed to failure or retry, depending on the error.</p><h3>Tags: </h3><p>put, parquet, hadoop, HDFS, filesystem, restricted</p><h3>Properties: </h3><p>In the list below, the names of required properties appear in <strong>bold</strong>. Any other properties (not in bold) are considered optional. The table also indicates any default values, and whether a property supports the <a href="/nifi-docs/html/expression-language-guide.html">NiFi Expression Language</a>.</p><table id="properties"><tr><th>Name</th><th>Default Value</th><th>Allowable Values</th><th>Description</th></tr><tr><td id="name">Hadoop Configuration Resources</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</td></tr><tr><td id="name">Kerberos Principal</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</td></tr><tr><td id="name">Kerberos Keytab</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</td></tr><tr><td id="name">Kerberos Relogin Period</td><td id="default-value">4 hours</td><td id="allowable-values"></td><td id="description">Period of time which should pass before attempting a kerberos relogin</td></tr><tr><td id="name">Additional Classpath Resources</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">A comma-separated list of paths to files and/or directories that will be added to the classpath. When specifying a directory, all files with in the directory will be added to the classpath, but further sub-directories will not be included.</td></tr><tr><td id="name"><strong>Record Reader</strong></td><td id="default-value"></td><td id="allowable-values"><strong>Controller Service API: </strong><br/>RecordReaderFactory<br/><strong>Implementations: </strong><a href="/nifi-docs/components/org.apache.nifi/nifi-record-serialization-services-nar/1.3.0/org.apache.nifi.grok.GrokReader/index.html">GrokReader</a><br/><a href="/nifi-docs/components/org.apache.nifi/nifi-record-serialization-services-nar/1.3.0/org.apache.nifi.avro.AvroReader/index.html">AvroReader</a><br/><a href="/nifi-docs/components/org.apache.nifi/nifi-record-serialization-services-nar/1.3.0/org.apache.nifi.csv.CSVReader/index.html">CSVReader</a><br/><a href="/nifi-docs/components/org.apache.nifi/nifi-record-serialization-services-nar/1.3.0/org.apache.nifi.json.JsonTreeReader/index.html">JsonTreeReader</a><br/><a href="/nifi-docs/components/org.apache.nifi/nifi-record-serialization-services-nar/1.3.0/org.apache.nifi.json.JsonPathReader/index.html">JsonPathReader</a><br/><a href="/nifi-docs/components/org.apache.nifi/nifi-scripting-nar/1.3.0/org.apache.nifi.record.script.ScriptedReader/index.html">ScriptedReader</a></td><td id="description">The service for reading records from incoming flow files.</td></tr><tr><td id="name"><strong>Directory</strong></td><td id="default-value"></td><td id="allowable-values"></td><td id="description">The parent directory to which files should be written. Will be created if it doesn't exist.<br/><strong>Supports Expression Language: true</strong></td></tr><tr><td id="name"><strong>Schema Access Strategy</strong></td><td id="default-value">schema-name</td><td id="allowable-values"><ul><li>Use 'Schema Name' Property <img src="/nifi-docs/html/images/iconInfo.png" alt="The name of the Schema to use is specified by the 'Schema Name' Property. The value of this property is used to lookup the Schema in the configured Schema Registry service." title="The name of the Schema to use is specified by the 'Schema Name' Property. The value of this property is used to lookup the Schema in the configured Schema Registry service."></img></li><li>Use 'Schema Text' Property <img src="/nifi-docs/html/images/iconInfo.png" alt="The text of the Schema itself is specified by the 'Schema Text' Property. The value of this property must be a valid Avro Schema. If Expression Language is used, the value of the 'Schema Text' property must be valid after substituting the expressions." title="The text of the Schema itself is specified by the 'Schema Text' Property. The value of this property must be a valid Avro Schema. If Expression Language is used, the value of the 'Schema Text' property must be valid after substituting the expressions."></img></li><li>HWX Schema Reference Attributes <img src="/nifi-docs/html/images/iconInfo.png" alt="The FlowFile contains 3 Attributes that will be used to lookup a Schema from the configured Schema Registry: 'schema.identifier', 'schema.version', and 'schema.protocol.version'" title="The FlowFile contains 3 Attributes that will be used to lookup a Schema from the configured Schema Registry: 'schema.identifier', 'schema.version', and 'schema.protocol.version'"></img></li><li>HWX Content-Encoded Schema Reference <img src="/nifi-docs/html/images/iconInfo.png" alt="The content of the FlowFile contains a reference to a schema in the Schema Registry service. The reference is encoded as a single byte indicating the 'protocol version', followed by 8 bytes indicating the schema identifier, and finally 4 bytes indicating the schema version, as per the Hortonworks Schema Registry serializers and deserializers, found at https://github.com/hortonworks/registry" title="The content of the FlowFile contains a reference to a schema in the Schema Registry service. The reference is encoded as a single byte indicating the 'protocol version', followed by 8 bytes indicating the schema identifier, and finally 4 bytes indicating the schema version, as per the Hortonworks Schema Registry serializers and deserializers, found at https://github.com/hortonworks/registry"></img></li></ul></td><td id="description">Specifies how to obtain the schema that is to be used for writing the data.</td></tr><tr><td id="name">Schema Registry</td><td id="default-value"></td><td id="allowable-values"><strong>Controller Service API: </strong><br/>SchemaRegistry<br/><strong>Implementations: </strong><a href="/nifi-docs/components/org.apache.nifi/nifi-registry-nar/1.3.0/org.apache.nifi.schemaregistry.services.AvroSchemaRegistry/index.html">AvroSchemaRegistry</a><br/><a href="/nifi-docs/components/org.apache.nifi/nifi-hwx-schema-registry-nar/1.3.0/org.apache.nifi.schemaregistry.hortonworks.HortonworksSchemaRegistry/index.html">HortonworksSchemaRegistry</a></td><td id="description">Specifies the Controller Service to use for the Schema Registry</td></tr><tr><td id="name">Schema Name</td><td id="default-value">${schema.name}</td><td id="allowable-values"></td><td id="description">Specifies the name of the schema to lookup in the Schema Registry property<br/><strong>Supports Expression Language: true</strong></td></tr><tr><td id="name">Schema Text</td><td id="default-value">${avro.schema}</td><td id="allowable-values"></td><td id="description">The text of an Avro-formatted Schema<br/><strong>Supports Expression Language: true</strong></td></tr><tr><td id="name"><strong>Compression Type</strong></td><td id="default-value">UNCOMPRESSED</td><td id="allowable-values"><ul><li>UNCOMPRESSED</li><li>SNAPPY</li><li>GZIP</li><li>LZO</li></ul></td><td id="description">The type of compression for the file being written.</td></tr><tr><td id="name"><strong>Overwrite Files</strong></td><td id="default-value">false</td><td id="allowable-values"><ul><li>true</li><li>false</li></ul></td><td id="description">Whether or not to overwrite existing files in the same directory with the same name. When set to false, flow files will be routed to failure when a file exists in the same directory with the same name.</td></tr><tr><td id="name">Permissions umask</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</td></tr><tr><td id="name">Remote Group</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</td></tr><tr><td id="name">Remote Owner</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</td></tr><tr><td id="name">Row Group Size</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">The row group size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.<br/><strong>Supports Expression Language: true</strong></td></tr><tr><td id="name">Page Size</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">The page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.<br/><strong>Supports Expression Language: true</strong></td></tr><tr><td id="name">Dictionary Page Size</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">The dictionary page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.<br/><strong>Supports Expression Language: true</strong></td></tr><tr><td id="name">Max Padding Size</td><td id="default-value"></td><td id="allowable-values"></td><td id="description">The maximum amount of padding that will be used to align row groups with blocks in the underlying filesystem. If the underlying filesystem is not a block filesystem like HDFS, this has no effect. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.<br/><strong>Supports Expression Language: true</strong></td></tr><tr><td id="name">Enable Dictionary Encoding</td><td id="default-value"></td><td id="allowable-values"><ul><li>true</li><li>false</li></ul></td><td id="description">Specifies whether dictionary encoding should be enabled for the Parquet writer</td></tr><tr><td id="name">Enable Validation</td><td id="default-value"></td><td id="allowable-values"><ul><li>true</li><li>false</li></ul></td><td id="description">Specifies whether validation should be enabled for the Parquet writer</td></tr><tr><td id="name">Writer Version</td><td id="default-value"></td><td id="allowable-values"><ul><li>PARQUET_1_0</li><li>PARQUET_2_0</li></ul></td><td id="description">Specifies the version used by Parquet writer</td></tr><tr><td id="name">Remove CRC Files</td><td id="default-value">false</td><td id="allowable-values"><ul><li>true</li><li>false</li></ul></td><td id="description">Specifies whether the corresponding CRC file should be deleted upon successfully writing a Parquet file</td></tr></table><h3>Relationships: </h3><table id="relationships"><tr><th>Name</th><th>Description</th></tr><tr><td>retry</td><td>Flow Files that could not be processed due to issues that can be retried are transferred to this relationship</td></tr><tr><td>success</td><td>Flow Files that have been successfully processed are transferred to this relationship</td></tr><tr><td>failure</td><td>Flow Files that could not be processed due to issue that cannot be retried are transferred to this relationship</td></tr></table><h3>Reads Attributes: </h3><table id="reads-attributes"><tr><th>Name</th><th>Description</th></tr><tr><td>filename</td><td>The name of the file to write comes from the value of this attribute.</td></tr></table><h3>Writes Attributes: </h3><table id="writes-attributes"><tr><th>Name</th><th>Description</th></tr><tr><td>filename</td><td>The name of the file is stored in this attribute.</td></tr><tr><td>absolute.hdfs.path</td><td>The absolute path to the file is stored in this attribute.</td></tr><tr><td>record.count</td><td>The number of records written to the Parquet file</td></tr></table><h3>State management: </h3>This component does not store state.<h3>Restricted: </h3>Provides operator the ability to write to any file that NiFi has access to in HDFS or the local filesystem.<h3>Input requirement: </h3>This component requires an incoming relationship.</body></html>